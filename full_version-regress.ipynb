{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate,MaxPooling2D,BatchNormalization\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random,pickle,cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18854"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=['f/'+ x for x in os.listdir('../f/')]\n",
    "labels=pickle.load(open('../fdata.pkl','rb'))\n",
    "val_files=pickle.load(open('../fval_files.pkl','rb'))\n",
    "random.shuffle(files)\n",
    "train_files=[f for f in files if f not in val_files and len(labels[f])>0]\n",
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Encoder\n",
    "inputs = Input(shape=(41472,))\n",
    "output2 = Dense(768, activation='relu')(inputs)\n",
    "output2=keras.layers.Dropout(0.2)(output2)\n",
    "output2 = Dense(300, activation='relu')(output2)\n",
    "output2=keras.layers.Dropout(0.2)(output2)\n",
    "output2 = Dense(100, activation='relu')(output2)\n",
    "output2=keras.layers.Dropout(0.2)(output2)\n",
    "predictions2 = Dense(2, activation='linear')(output2)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs ,outputs=predictions2)\n",
    "#model = Model(inputs=[input,embed_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Generate training data\n",
    "batch_size = 20\n",
    "\n",
    "def train_gen(batch_size,model1):\n",
    "    while True:\n",
    "        i=random.randint(0,len(train_files)-batch_size-1)\n",
    "        names=train_files[i:i+batch_size]\n",
    "        X_batch, Y_batch=generator(names,model1)\n",
    "        yield (X_batch, Y_batch)\n",
    "        \n",
    "def val_gen(model1):\n",
    "    names=val_files\n",
    "    \n",
    "    X_batch, Y_batch=generator(names,model1)\n",
    "    while True:\n",
    "            yield (X_batch,Y_batch)\n",
    "def generator(names,model1):\n",
    "    X_batch=[]\n",
    "    Y_batch=[]\n",
    "    embed = []\n",
    "    for filename in names:\n",
    "        X_batch.append(img_to_array(load_img('../'+filename))/255)\n",
    "        d=[]\n",
    "        if(len(labels[filename])>0):    \n",
    "            d+=[1,labels[filename][0]/299.0,labels[filename][1]/299.0]\n",
    "        if(len(d)<3):\n",
    "            d=[0,0,0]\n",
    "        Y_batch.append(d)    \n",
    "    X_batch=np.array(X_batch)\n",
    "    embed=create_embedding(model1,X_batch)\n",
    "    Y_batch=np.array(Y_batch)\n",
    "    #embed=create_inception_embedding(X_batch)\n",
    "    return embed, Y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f2_score(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    return keras.losses.binary_crossentropy(y_true,y_pred)\n",
    "\n",
    "def loss2(y_true, y_pred):\n",
    "    A=y_pred[:,0]*y_true[:,0]\n",
    "    B=y_pred[:,1]*y_true[:,0]\n",
    "    a=K.sum(K.square(A-y_true[:,1]))+K.sum(K.square(B-y_true[:,2]))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1=load_model('model3.hdf5', custom_objects={'loss': loss,'f2_score':f2_score})\n",
    "def create_embedding(model1,x):\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "            get_3rd_layer_output = K.function([model1.layers[0].input],\n",
    "                                  [model1.layers[-8].output])\n",
    "            layer_output = get_3rd_layer_output([x])[0]\n",
    "    return layer_output\n",
    "\n",
    "def get_3rd_layer_output(model1,x):\n",
    "    global graph\n",
    "    with graph.as_default():\n",
    "            get_3rd_layer_output = K.function([model1.layers[0].input],\n",
    "                                  [model1.layers[-1].output])\n",
    "            layer_output = get_3rd_layer_output([x])[0]\n",
    "    return layer_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam=keras.optimizers.Adam(lr=0.00001)\n",
    "tensorboard = TensorBoard(log_dir=\"./output\")\n",
    "model.compile(optimizer=adam, loss=loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_decay(step):\n",
    "   initial_lrate = 0.0001\n",
    "   final_lrate=0.00001\n",
    "   lrate = (initial_lrate-final_lrate)*step/150\n",
    "   print(initial_lrate-lrate)\n",
    "   return initial_lrate-lrate\n",
    "\n",
    "lrate = keras.callbacks.LearningRateScheduler(exp_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "40/40 [==============================] - 34s 860ms/step - loss: 0.8578 - val_loss: 0.9412\n",
      "Epoch 2/150\n",
      "40/40 [==============================] - 36s 907ms/step - loss: 0.8802 - val_loss: 0.9766\n",
      "Epoch 3/150\n",
      "40/40 [==============================] - 38s 945ms/step - loss: 0.7291 - val_loss: 0.9578\n",
      "Epoch 4/150\n",
      "40/40 [==============================] - 35s 869ms/step - loss: 0.7772 - val_loss: 0.9487\n",
      "Epoch 5/150\n",
      "40/40 [==============================] - 35s 877ms/step - loss: 1.7272 - val_loss: 0.9346\n",
      "Epoch 6/150\n",
      "40/40 [==============================] - 34s 843ms/step - loss: 0.8239 - val_loss: 0.9146\n",
      "Epoch 7/150\n",
      "40/40 [==============================] - 37s 934ms/step - loss: 0.7481 - val_loss: 0.9167\n",
      "Epoch 8/150\n",
      "40/40 [==============================] - 36s 904ms/step - loss: 0.8239 - val_loss: 0.9374\n",
      "Epoch 9/150\n",
      "40/40 [==============================] - 38s 941ms/step - loss: 0.7943 - val_loss: 0.9501\n",
      "Epoch 10/150\n",
      "40/40 [==============================] - 36s 890ms/step - loss: 0.8800 - val_loss: 0.9454\n",
      "Epoch 11/150\n",
      "40/40 [==============================] - 38s 944ms/step - loss: 0.8665 - val_loss: 0.9729\n",
      "Epoch 12/150\n",
      "40/40 [==============================] - 48s 1s/step - loss: 0.7849 - val_loss: 0.9403\n",
      "Epoch 13/150\n",
      "40/40 [==============================] - 40s 998ms/step - loss: 0.7845 - val_loss: 0.8982\n",
      "Epoch 14/150\n",
      "40/40 [==============================] - 40s 994ms/step - loss: 0.7352 - val_loss: 0.9621\n",
      "Epoch 15/150\n",
      "40/40 [==============================] - 39s 982ms/step - loss: 0.7272 - val_loss: 0.9516\n",
      "Epoch 16/150\n",
      "40/40 [==============================] - 38s 960ms/step - loss: 0.8203 - val_loss: 0.9006\n",
      "Epoch 17/150\n",
      "40/40 [==============================] - 36s 901ms/step - loss: 0.7217 - val_loss: 0.9456\n",
      "Epoch 18/150\n",
      "40/40 [==============================] - 37s 923ms/step - loss: 0.7912 - val_loss: 0.9358\n",
      "Epoch 19/150\n",
      "40/40 [==============================] - 38s 953ms/step - loss: 0.8035 - val_loss: 0.9274\n",
      "Epoch 20/150\n",
      "40/40 [==============================] - 38s 956ms/step - loss: 0.7120 - val_loss: 0.9303\n",
      "Epoch 21/150\n",
      " 3/40 [=>............................] - ETA: 33s - loss: 0.5931"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Train model      \n",
    "\n",
    "model.fit_generator(train_gen(batch_size,model1), epochs=150,steps_per_epoch=40,validation_data=val_gen(model1),validation_steps=1, max_queue_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model3regress.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model3regress.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y=next(train_gen(1,model1))\n",
    "Y=model.predict(create_embedding(model1,x))\n",
    "Y1=model1.predict(x)\n",
    "print(Y.shape,Y1.shape)\n",
    "if Y1[0]>0.5:\n",
    "    print(Y[0])\n",
    "    cv2.circle(x[0],tuple(map(int,Y[0]*299)),1,(0,255,0),5)\n",
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotRec(vec,Y):\n",
    "    index=np.argsort(Y,axis=0)[::-1]\n",
    "    print(Y[index])\n",
    "    x=vec[index]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 93 139 140\n",
      "(294, 299, 299, 3)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[294,32,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_12_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_12_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_12_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: reshape_2_1/Reshape/_20077 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_401_reshape_2_1/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ae1984672bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplotRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7ee272cf5511>\u001b[0m in \u001b[0;36mcreate_embedding\u001b[0;34m(model1, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m             get_3rd_layer_output = K.function([model1.layers[0].input],\n\u001b[1;32m      6\u001b[0m                                   [model1.layers[-8].output])\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_3rd_layer_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[0;32m-> 1454\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[294,32,299,299] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_12_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_12_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_12_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: reshape_2_1/Reshape/_20077 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_401_reshape_2_1/Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "def manipulateImage(img):\n",
    "    height=299*(1+(img.shape[0]//299))\n",
    "    width=299*(1+(img.shape[1]//299))\n",
    "    h=height-img.shape[0]\n",
    "    w=width-img.shape[1]\n",
    "    print( h//2, h-(h//2), w//2, w-(w//2))\n",
    "    image = cv2.copyMakeBorder( img, h//2, h-(h//2), w//2, w-(w//2), cv2.BORDER_CONSTANT)\n",
    "    #plt.imshow(img)\n",
    "    vec=[]\n",
    "    for x in range(width//299):\n",
    "        for y in range(height//299):\n",
    "            vec.append(image[299*y:299*(y+1),299*x:299*(x+1)])\n",
    "    return np.array(vec)\n",
    "\n",
    "vec=manipulateImage(img_to_array(load_img('../CV-Assignment-Dataset/DSC01453.JPG'))/255)\n",
    "print(vec.shape)\n",
    "\n",
    "Y=model.predict(create_embedding(model1,vec))\n",
    "model.predict(vec)\n",
    "vec=plotRec(vec,model.predict(vec))\n",
    "# import time\n",
    "f=plt.figure(figsize=(10,25))\n",
    "i=1\n",
    "for x in vec[:5]:\n",
    "    print(x.shape)\n",
    "    f.add_subplot(5,1,i)\n",
    "    plt.imshow(x[0])\n",
    "    i+=1\n",
    "\n",
    "    #     time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(495e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
